{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import RetrievalQA\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "#from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain.llms import GPT4All\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "#from langchain.vectorstores import Chroma\n",
    "from langchain_chroma import Chroma\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Knowledge Base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of pages of the document: 16\n",
      "number of pages of the knowledgeBase: 16\n"
     ]
    }
   ],
   "source": [
    "#load pdf file\n",
    "loader3 = PyPDFLoader(\"BodyPartRecognition.pdf\") #your pdf file path\n",
    "papper = loader3.load_and_split()\n",
    "print(f\"number of pages of the document: {len(papper)}\")\n",
    "knowledgeBase=papper\n",
    "print(f\"number of pages of the knowledgeBase: {len(knowledgeBase)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chunking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56\n"
     ]
    }
   ],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1024, chunk_overlap=64)\n",
    "texts_1024 = text_splitter.split_documents(knowledgeBase)\n",
    "print(len(texts_1024))\n",
    "#print(texts_1024[0].page_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embedings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#chose emmbedings model\n",
    "#model_ = HuggingFaceEmbeddings(model_name=\"google-bert/bert-base-uncased\")\n",
    "#model_ = HuggingFaceEmbeddings(model_name= \"sentence-transformers/all-roberta-large-v1\")\n",
    "model_ = HuggingFaceEmbeddings(model_name=\"sentence-transformers/msmarco-bert-base-dot-v5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embeddings in DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_name = \"chroma_db_wizard\"\n",
    "db_path = os.path.join(db_name)\n",
    "if os.path.exists(db_path):\n",
    "    db=Chroma(persist_directory=\"chroma_db_wizard\", embedding_function=model_)\n",
    "else:\n",
    "    db = Chroma.from_documents(texts_1024, model_, persist_directory=\"chroma_db_wizard\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#local model path\n",
    "model_path = \"C:/Users/Ridvan/AppData/Local/nomic.ai/GPT4All/Llama-3.2-3B-Instruct-Q4_0.gguf\"\n",
    "\n",
    "# Callbacks\n",
    "callbacks = [StreamingStdOutCallbackHandler()]\n",
    "\n",
    "llm= GPT4All(model=model_path, callbacks=callbacks, verbose=True,n_threads=16, temp=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Promp Template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template='''\n",
    "You can access the context between BEGININPUT and ENDINPUT tags for the following task. Answer the following question in English and only based on the given context. If these do not contain an answer, say that no answer is possible based on the information given!\n",
    "USER: \n",
    "BEGININPUT{context}ENDINPUT\n",
    "BEGINING {question} END \n",
    "ASSISTANT:\n",
    "'''\n",
    "PROMPT=PromptTemplate(\n",
    "    template=prompt_template,input_variables=[\"context\",\"question\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain_type_kwargs={\"prompt\":PROMPT}\n",
    "qa_RAG_chain =RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    chain_type=\"stuff\",\n",
    "    retriever=db.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 3}),\n",
    "    return_source_documents=True,\n",
    "    verbose=False,\n",
    "    chain_type_kwargs=chain_type_kwargs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The subject of the article appears to be a research work related to computer vision and human-computer interaction, specifically focusing on body part labeling using depth cameras. \n",
      "\n",
      "However, I must point out that there seems to be no clear answer within the provided context. The text does not explicitly state what the main topic or subject is.\n",
      "\n",
      "If you'd like, I can try to provide a possible interpretation based on the content, but please note that it might not be entirely accurate without more information. \n",
      "\n",
      "Would you like me to attempt an interpretation?"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"The subject of the article appears to be a research work related to computer vision and human-computer interaction, specifically focusing on body part labeling using depth cameras. \\n\\nHowever, I must point out that there seems to be no clear answer within the provided context. The text does not explicitly state what the main topic or subject is.\\n\\nIf you'd like, I can try to provide a possible interpretation based on the content, but please note that it might not be entirely accurate without more information. \\n\\nWould you like me to attempt an interpretation?\""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#qa_RAG_chain.invoke(\"what is experiments results?\")[\"result\"]\n",
    "qa_RAG_chain.invoke(\"What is the subject of the article?\")[\"result\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cudaPytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
