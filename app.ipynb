{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import RetrievalQA\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.llms import GPT4All\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Knowledge Base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of pages of the document: 16\n",
      "number of pages of the knowledgeBase: 16\n"
     ]
    }
   ],
   "source": [
    "#load pdf file\n",
    "loader3 = PyPDFLoader(\"BodyPartRecognition.pdf\") #your pdf file path\n",
    "papper = loader3.load_and_split()\n",
    "print(f\"number of pages of the document: {len(papper)}\")\n",
    "knowledgeBase=papper\n",
    "print(f\"number of pages of the knowledgeBase: {len(knowledgeBase)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chunking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56\n"
     ]
    }
   ],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1024, chunk_overlap=64)\n",
    "texts_1024 = text_splitter.split_documents(knowledgeBase)\n",
    "print(len(texts_1024))\n",
    "#print(texts_1024[0].page_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embedings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ridvan\\AppData\\Local\\Temp\\ipykernel_1236\\1527794672.py:2: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  model_ = HuggingFaceEmbeddings(model_name=\"google-bert/bert-base-uncased\")\n",
      "c:\\Users\\Ridvan\\anaconda3\\envs\\cudaPytorch\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "No sentence-transformers model found with name google-bert/bert-base-uncased. Creating a new one with mean pooling.\n"
     ]
    }
   ],
   "source": [
    "#chose emmbedings model\n",
    "model_ = HuggingFaceEmbeddings(model_name=\"google-bert/bert-base-uncased\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embeddings in DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ridvan\\AppData\\Local\\Temp\\ipykernel_1236\\654599481.py:4: LangChainDeprecationWarning: The class `Chroma` was deprecated in LangChain 0.2.9 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-chroma package and should be used instead. To use it run `pip install -U :class:`~langchain-chroma` and import as `from :class:`~langchain_chroma import Chroma``.\n",
      "  db=Chroma(persist_directory=\"chroma_db_wizard\", embedding_function=model_)\n"
     ]
    }
   ],
   "source": [
    "db_name = \"chroma_db_wizard\"\n",
    "db_path = os.path.join(db_name)\n",
    "if os.path.exists(db_path):\n",
    "    db=Chroma(persist_directory=\"chroma_db_wizard\", embedding_function=model_)\n",
    "else:\n",
    "    db = Chroma.from_documents(texts_1024, model_, persist_directory=\"chroma_db_wizard\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#local model path\n",
    "model_path = \"C:/Users/Ridvan/AppData/Local/nomic.ai/GPT4All/Llama-3.2-3B-Instruct-Q4_0.gguf\"\n",
    "\n",
    "# Callbacks\n",
    "callbacks = [StreamingStdOutCallbackHandler()]\n",
    "\n",
    "llm= GPT4All(model=model_path, callbacks=callbacks, verbose=True,n_threads=16, temp=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Promp Template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "prompt_template='''\n",
    "You can access the context between BEGININPUT and ENDINPUT tags for the following task. Answer the following question in English only, based on the given context. If these do not contain an answer, say that no answer is possible based on the information given!\n",
    "USER: \n",
    "BEGININPUT{context}ENDINPUT\n",
    "BEGINING {question} END \n",
    "ASSISTANT:\n",
    "'''\n",
    "PROMPT=PromptTemplate(\n",
    "    template=prompt_template,input_variables=[\"context\",\"question\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain_type_kwargs={\"prompt\":PROMPT}\n",
    "qa_RAG_chain =RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    chain_type=\"stuff\",\n",
    "    retriever=db.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 3}),\n",
    "    return_source_documents=True,\n",
    "    verbose=False,\n",
    "    chain_type_kwargs=chain_type_kwargs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The experiment's results are as follows:\n",
      "\n",
      "1. **Classification Accuracy**: Our approach achieved an average classification accuracy of 95% on the synthetic test set and 92% on the real test set.\n",
      "2. **Joint Prediction Accuracy**: The joint prediction accuracy was higher for the synthetic test set, with an average accuracy of 98%, compared to 94% for the real test set.\n",
      "3. **Rotation Effect**: We found that the rotation effect had a significant impact on both classification and joint prediction accuracy, with errors increasing by up to 20% when rotating beyond ±120°.\n",
      "4. **Full 360° Scenario Evaluation**: Evaluating our approach in the full 360° scenario resulted in lower performance compared to the limited rotation scenario.\n",
      "\n",
      "These results indicate that our semi-local body part classifier can generalize well across a wide range of poses and scenarios, with some limitations observed when considering extreme variability or rotations beyond ±120°."
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"The experiment's results are as follows:\\n\\n1. **Classification Accuracy**: Our approach achieved an average classification accuracy of 95% on the synthetic test set and 92% on the real test set.\\n2. **Joint Prediction Accuracy**: The joint prediction accuracy was higher for the synthetic test set, with an average accuracy of 98%, compared to 94% for the real test set.\\n3. **Rotation Effect**: We found that the rotation effect had a significant impact on both classification and joint prediction accuracy, with errors increasing by up to 20% when rotating beyond ±120°.\\n4. **Full 360° Scenario Evaluation**: Evaluating our approach in the full 360° scenario resulted in lower performance compared to the limited rotation scenario.\\n\\nThese results indicate that our semi-local body part classifier can generalize well across a wide range of poses and scenarios, with some limitations observed when considering extreme variability or rotations beyond ±120°.\""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qa_RAG_chain.invoke(\"what is experiments results?\")[\"result\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cudaPytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
